{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ellio\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "# Assuming this script is in the same directory level as the 'input' folder\n",
    "input_dir = os.path.join(os.getcwd(), 'input')\n",
    "classes = ['input/Rook-resize', 'input/pawn_resized', 'input/knight-resize', 'input/Queen-Resized', 'input/bishop_resized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_builder(clss):\n",
    "    lst = []\n",
    "    for img in os.listdir(clss):\n",
    "        f = cv2.imread(os.path.join(clss, img), cv2.IMREAD_GRAYSCALE)\n",
    "        f = cv2.resize(f, (100, 100))\n",
    "        f = f / 255.0\n",
    "        lst.append(f)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for c in classes:\n",
    "    features += feature_builder(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "X = X.reshape(-1, 100, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i, c in enumerate(classes):\n",
    "    labels += [i] * len(os.listdir(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch creation for Vision Transformer\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID',\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch encoding for Vision Transformer\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP layer creator\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision Transformer (ViT) Model\n",
    "def create_vit_classifier():\n",
    "    input_shape = (100, 100, 1)\n",
    "    num_classes = 5\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Create patches\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (100 // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "transformer_layers = 8\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n",
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ellio\\Desktop\\MLChessPieceClassification\\transformer-chess-notebook.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Model Compilation\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vit_classifier \u001b[39m=\u001b[39m create_vit_classifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m vit_classifier\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\ellio\\Desktop\\MLChessPieceClassification\\transformer-chess-notebook.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     x2 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mAdd()([attention_output, encoded_patches])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     x3 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mLayerNormalization(epsilon\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m)(x2)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x3 \u001b[39m=\u001b[39m mlp(x3, hidden_units\u001b[39m=\u001b[39mtransformer_units, dropout_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     encoded_patches \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mAdd()([x3, x2])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ellio/Desktop/MLChessPieceClassification/transformer-chess-notebook.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Create a [batch_size, projection_dim] tensor\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Compilation\n",
    "vit_classifier = create_vit_classifier()\n",
    "vit_classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "history = vit_classifier.fit(\n",
    "    X_train, Y_train, batch_size=32, epochs=20, validation_split=0.1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
